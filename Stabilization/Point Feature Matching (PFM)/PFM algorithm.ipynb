{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import time\n",
    "import math\n",
    "from skimage import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a smoothing function based on convolution\n",
    "def curveSmoothing(curve, radius):\n",
    "    \n",
    "    # Define filter\n",
    "    window_size = 2 * radius + 1\n",
    "    fltr = np.ones(window_size) / window_size\n",
    "    \n",
    "    # Add padding to the boundaries\n",
    "    curve_pad = np.lib.pad(curve, (radius, radius), \"edge\")\n",
    "    # Apply convolution\n",
    "    curve_smoothed = np.convolve(curve_pad, fltr, mode=\"same\")\n",
    "    # Remove padding\n",
    "    curve_smoothed = curve_smoothed[radius:-radius]\n",
    "    \n",
    "    return curve_smoothed\n",
    "\n",
    "def smooth(trajectory, radius):\n",
    "    smoothed_trajectory = np.copy(trajectory)\n",
    "    # Applying smoothing function to the dx, dy and rotation angle curves\n",
    "    for i in range(3):\n",
    "        smoothed_trajectory[:,i] = curveSmoothing(trajectory[:,i], radius)\n",
    "    return smoothed_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFramesCount(cap):\n",
    "    count = 0\n",
    "    while True:\n",
    "        res, frame = cap.read()\n",
    "        if not res:\n",
    "            break\n",
    "        count += 1\n",
    "    cap.set(cv.CAP_PROP_POS_AVI_RATIO, 0)\n",
    "    return count\n",
    "\n",
    "def getMetadata(filename):\n",
    "    # Define video size in bytes\n",
    "    s1 = os.path.getsize(filename)\n",
    "    s2 = os.stat(filename).st_size\n",
    "    s3 = Path(filename).stat().st_size\n",
    "    s_list = [s1, s2, s3]\n",
    "\n",
    "    # Define video duration\n",
    "    time_cap = cv.VideoCapture(filename)\n",
    "    n_frames = getFramesCount(time_cap)\n",
    "\n",
    "    fps = time_cap.get(cv.CAP_PROP_FPS)\n",
    "    \n",
    "    time_cap.release()\n",
    "\n",
    "    duration = n_frames / fps\n",
    "\n",
    "    # Calculate bitrate\n",
    "    bitrate = s1 / (125 * duration)\n",
    "    print(f\"Bitrate: {round(bitrate)} kbps\")\n",
    "    \n",
    "    return [s1, duration, bitrate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics functions\n",
    "def rmse(frame1, frame2, w, h):\n",
    "    return math.sqrt(np.sum((frame1.astype(\"float\") - frame2.astype(\"float\")) ** 2) / (w * h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Стабилизация видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stabilizeVideo(filename, params, output_name):\n",
    "    maxCorners, qualityLevel, minDistance, blockSize, radius, scale = params\n",
    "    \n",
    "    # Read input video\n",
    "    cap = cv.VideoCapture(filename)\n",
    "    \n",
    "    n_frames = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Frames count: {n_frames}\")\n",
    "\n",
    "    # Get width and height of video stream\n",
    "    w = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(f\"Video size: {w}×{h} pixels\")\n",
    "\n",
    "    # Get video stream fps\n",
    "    fps = cap.get(cv.CAP_PROP_FPS)\n",
    "    print(f\"Video fps: {fps:.5} frames per second\")\n",
    "    \n",
    "    # Define the codec for output video\n",
    "    fourcc = cv.VideoWriter_fourcc(*\"I420\")\n",
    "    \n",
    "    # Set up output video\n",
    "    out = cv.VideoWriter(output_name, fourcc, fps, (w, h))\n",
    "    \n",
    "    # Read first frame\n",
    "    res, prev_frame = cap.read()\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    prev_frame = cv.cvtColor(prev_frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Pre-define transformation-store array\n",
    "    transforms = np.zeros((n_frames - 1, 3), np.float32)\n",
    "    \n",
    "    # Find the transformations between the frames\n",
    "    for i in range(n_frames - 1):\n",
    "\n",
    "        # Detect feature points in previous frame\n",
    "        \"\"\" \n",
    "        Parametrs:\n",
    "\n",
    "            maxCorners — maximum number of corners to return; if there are more corners than are found, \n",
    "                         the strongest of them are returned.\n",
    "\n",
    "            qualityLevel — parameter characterizing the minimal accepted quality of image corners;\n",
    "                            the corners with the quality measure less than the (quality_level * best_corener_quality_measure)\n",
    "                            are rejected.\n",
    "\n",
    "            minDistance — minimum possible Euclidean distance between the returned corners\n",
    "\n",
    "            blockSize — size of block for computing derivative matrix over each pixel neighborhood (sliding window) \n",
    "        \"\"\" \n",
    "        prev_frame_points = cv.goodFeaturesToTrack(prev_frame, maxCorners, qualityLevel, minDistance, blockSize)\n",
    "\n",
    "        # Read next frame\n",
    "        res, curr_frame = cap.read()\n",
    "        if not res:\n",
    "            print(f\"Error: {i} frame\")\n",
    "            break\n",
    "\n",
    "        curr_frame = cv.cvtColor(curr_frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate optical flow\n",
    "        curr_frame_points, status, err = cv.calcOpticalFlowPyrLK(prev_frame, curr_frame, prev_frame_points, None)\n",
    "\n",
    "        # Sanity check\n",
    "        assert prev_frame_points.shape == curr_frame_points.shape\n",
    "\n",
    "        # Filter only valid points\n",
    "        mask = np.where(status == 1)[0]\n",
    "        prev_frame_points = prev_frame_points[mask]\n",
    "        curr_frame_points = curr_frame_points[mask]\n",
    "\n",
    "        # Find transformation matrix\n",
    "        transform_matrix = cv.estimateAffinePartial2D(prev_frame_points, curr_frame_points)[0]\n",
    "\n",
    "        # Extract translation\n",
    "        dx = transform_matrix[0, 2]\n",
    "        dy = transform_matrix[1, 2]\n",
    "\n",
    "        # Extract rotation angel\n",
    "        da = np.arctan2(transform_matrix[1, 0], transform_matrix[0, 0])\n",
    "\n",
    "        # Store transformation\n",
    "        transforms[i] = [dx, dy, da]\n",
    "\n",
    "        # Move to next frame\n",
    "        prev_frame = curr_frame\n",
    "\n",
    "        print(f\"Frame {i + 2}/{n_frames} — tracked points: {len(curr_frame_points)}\")\n",
    "    \n",
    "    # Compute trajectory using cumulative sum of transforms\n",
    "    trajectory = np.cumsum(transforms, axis=0)\n",
    "\n",
    "    # Compute smoothed trajectory\n",
    "    smoothed_trajectory = smooth(trajectory, radius)\n",
    "\n",
    "    # Calculate difference in smoothed_trajectory and trajectory\n",
    "    diff = smoothed_trajectory - trajectory\n",
    "\n",
    "    # Calculate new transformations array\n",
    "    smoothed_transforms = transforms + diff\n",
    "    \n",
    "    # Initialize metrics\n",
    "    average_rmse = 0.0\n",
    "    average_ssim = 0.0\n",
    "\n",
    "    # Reset stream to first frame\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "    res, prev_frame = cap.read()\n",
    "    out.write(prev_frame)\n",
    "    prev_frame = cv.cvtColor(prev_frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Write n-1 transformed frames\n",
    "    for i in range(n_frames - 1):\n",
    "        # Read next frame\n",
    "        res, curr_frame = cap.read()\n",
    "        if not res:\n",
    "            print(f\"Error: {i} frame\")\n",
    "            break\n",
    "\n",
    "        # Extract transformations from the transformations array\n",
    "        dx = smoothed_transforms[i, 0]\n",
    "        dy = smoothed_transforms[i, 1]\n",
    "        da = smoothed_transforms[i, 2]\n",
    "\n",
    "        # Reconstruct transformation matrix\n",
    "        transform_matrix = np.zeros((2,3),np.float32)\n",
    "        transform_matrix[0,0] = np.cos(da)\n",
    "        transform_matrix[0,1] = -np.sin(da)\n",
    "        transform_matrix[1,0] = np.sin(da)\n",
    "        transform_matrix[1,1] = np.cos(da)\n",
    "        transform_matrix[0,2] = dx\n",
    "        transform_matrix[1,2] = dy\n",
    "\n",
    "        # Apply affine wrapping to the given frame\n",
    "        frame_stabilized = cv.warpAffine(curr_frame, transform_matrix, (w,h))\n",
    "\n",
    "        # Fix border artifacts by scaling the image without moving the center \n",
    "        s = frame_stabilized.shape\n",
    "        T = cv.getRotationMatrix2D((s[1]/2, s[0]/2), 0, 1.08)\n",
    "        frame_stabilized = cv.warpAffine(frame_stabilized, T, (w, h))\n",
    "\n",
    "        out.write(frame_stabilized)\n",
    "\n",
    "        # Calculate metrics\n",
    "        curr_frame = cv.cvtColor(frame_stabilized, cv.COLOR_BGR2GRAY)\n",
    "        average_rmse += rmse(curr_frame, prev_frame, w, h)\n",
    "\n",
    "        prev_frame = curr_frame\n",
    "    \n",
    "    # Calculate final metrics scores\n",
    "    average_rmse /= n_frames - 1\n",
    "    \n",
    "    # When everything is done release all captuerd objects\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "    return average_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAX_CORNERS = [100, 150, 200]\n",
    "QUALITY_LEVEL = [0.01, 0.1, 0.25]\n",
    "MIN_DISTANCE = [10, 30, 60]\n",
    "BLOCK_SIZE = [3, 5, 9]\n",
    "RADIUS = [50, 75, 100]\n",
    "SCALE = [1.04, 1.06, 1.08]\n",
    "BIG_B = 1e+6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_rmse = [BIG_B for i in range(5)]\n",
    "best_videos = [\"\" for i in range(5)]\n",
    "best_params = [[] for i in range(5)]\n",
    "\n",
    "index = 0\n",
    "\n",
    "for max_corners in MAX_CORNERS:\n",
    "    for quality_level in QUALITY_LEVEL:\n",
    "        for min_distance in MIN_DISTANCE:\n",
    "            for block_size in BLOCK_SIZE:\n",
    "                for radius in RADIUS:\n",
    "                    \n",
    "                    input_name = \"in/piano_boy.avi\"\n",
    "                    output_name = \"out/piano_boy_stabilized_example_\" + str(index) + \".avi\"\n",
    "                    \n",
    "                    scale = SCALE[RADIUS.index(radius)]\n",
    "                    params = [max_corners, quality_level, min_distance, block_size, radius, scale]\n",
    "                    \n",
    "                    video_rmse = stabilizeVideo(input_name, params, output_name)\n",
    "                    \n",
    "                    max_best = max(best_rmse)\n",
    "                    i_max = best_rmse.index(max_best)\n",
    "                    if video_rmse < max_best:\n",
    "                        best_rmse[i_max] = video_rmse\n",
    "                        if best_videos[i_max] != \"\":\n",
    "                            os.remove(best_videos[i_max])\n",
    "                            # time.sleep(3)\n",
    "                        best_videos[i_max] = output_name\n",
    "                        best_params[i_max] = params\n",
    "                    else:\n",
    "                        os.remove(output_name)\n",
    "                        # time.sleep(3)\n",
    "                    \n",
    "                    index += 1\n",
    "                    print(f\"Index: {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Best videos and their parametrs:\")\n",
    "for i in range (len(best_videos)):\n",
    "    print(f\"File name: {best_videos[i]} | RMSE: {best_rmse[i]}\")\n",
    "    print(f\" maxCorners: {best_params[i][0]}, qualityLevel: {best_params[i][1]}, minDistance: {best_params[i][2]}, blockSize: {best_params[i][3]},radius: {best_params[i][4]}, scale: {best_params[i][5]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
